---
title: "p8105_hw2_sc5558"
output: github_document
---
```{r setup, message=FALSE}
library(tidyverse)
library(janitor)
library(readxl)
library(lubridate)
```

## Problem 1 
```{r}
# Problem 1

## 1. Clean pols data
pols =
  read_csv("data/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(
    president = if_else(prez_gop == 1, "gop", "dem")
  ) |>
  select(-day, -prez_gop, -prez_dem) |>
  arrange(year, month)

## 2. Clean snp data
snp =
  read_csv("data/snp.csv") |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  select(year, month, close) |>
  arrange(year, month)

## 3. Clean unemployment data
unemployment =
  read_csv("data/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(
    month = str_to_title(month),        # e.g. "Jan" → "Jan"
    month = match(month, month.abb)     # convert abbrev to number 1–12
  ) |>
  arrange(year, month)

## 4. Merge datasets
merged_df =
  pols |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment, by = c("year", "month"))
## 5. Check structure
dim(merged_df)
range(merged_df$year)
names(merged_df)
```
## Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

The merged dataset contains 822 monthly observations and 11 key variables. The year ranges from 1947 to 2015. In addition, the names of the variables include year, month, gov_gop, sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close, and unemployment. 

## Problem 2
```{r}
# Problem 2

## 1. Mr. Trash Wheel
mr_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = "A2:N586") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "mr",
    sports_balls = as.integer(round(sports_balls, 0))
  )

## Mr. Trash Wheel
mr_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             skip = 1) |>   # skips the header note row
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "mr",
    year = as.integer(year),
    sports_balls = as.integer(round(sports_balls, 0))
  )

## Professor Trash Wheel
prof_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "professor",
    year = as.integer(year),
  )

## Captain Trash Wheel
captain_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Captain Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "captain",
    year = as.integer(year),
  )

## Gwynns Falls Trash Wheel
gwynns_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "gwynns_falls",
    year = as.integer(year),
  )
## Combine all
trash_df =
  bind_rows(mr_df, prof_df, captain_df, gwynns_df)
```
## Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?
```{r}
## Summaries for Problem 2

# Total weight collected by Professor Trash Wheel
prof_total_weight =
  trash_df |>
  filter(wheel == "professor") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

# Cigarette butts collected by Gwynns Falls in June 2022
gwynns_cig_butts =
  trash_df |>
  filter(wheel == "gwynns_falls", year == 2022, month == "June") |>
  summarise(total_cig_butts = sum(cigarette_butts, na.rm = TRUE))

```
The combined Trash Wheel dataset contains `r nrow(trash_df)` observations across `r ncol(trash_df)` variables, representing dumpster-specific collections from Mr., Professor, Captain, and Gwynns Falls Trash Wheels. Key variables include the collection date `(month, year)`, the amount of trash collected in `weight_tons` and `volume_cubic_yards`, and counts of items such as `plastic_bottles`, `cigarette_butts`, and `wrappers`. Professor Trash Wheel collected a total of `r prof_total_weight$total_weight` tons of trash. In June 2022, the Gwynns Falls Trash Wheel collected `r gwynns_cig_butts$total_cig_butts` cigarette butts. This tidy dataset provides a comprehensive view of waste accumulation and composition across multiple locations in Baltimore’s waterways.
## Problem 3
```{r}
library(tidyverse)
library(janitor)
library(lubridate)
library(glue)

# 1. Read and tidy the Zillow ZORI dataset
zori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  pivot_longer(
    cols = starts_with("20"),             # includes all dates like "2020-01-31"
    names_to = "date",
    values_to = "rent_index"
  ) |>
  mutate(
    date = ymd(date),
    year = year(date),
    month = month(date),
    ym = str_c(year, sprintf("%02d", month), sep = "_"),
    zip_code = as.character(RegionName)
  ) |>
  select(zip_code, date, year, month, ym, rent_index)

# 2. Read and clean ZIP code metadata
zip_df =
  read_csv("data/Zip Codes.csv") |>
  clean_names() |>
  rename(
    zip_code = zip_code,
    county = county,
    neighborhood = neighborhood
  ) |>
  mutate(zip_code = as.character(zip_code))

# 3. Merge both datasets
nyc_rent_df =
  left_join(zori_df, zip_df, by = "zip_code") |>
  relocate(zip_code, county, neighborhood, date, rent_index)

# 4. Summary statistics
n_obs = nrow(nyc_rent_df)
n_zip = n_distinct(nyc_rent_df$zip_code)
n_neigh = n_distinct(nyc_rent_df$neighborhood)

# 5. Identify ZIP codes missing from Zillow dataset
missing_zips =
  anti_join(zip_df, zori_df, by = "zip_code") |>
  select(zip_code, county, neighborhood)

# 6. COVID rent drop analysis: Jan 2020 vs Jan 2021
covid_drop =
  nyc_rent_df |>
  filter(ym %in% c("2020_01", "2021_01")) |>
  select(zip_code, county, neighborhood, ym, rent_index) |>
  group_by(zip_code, county, neighborhood, ym) |>
  summarise(
    rent_index = mean(rent_index, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = ym,
    values_from = rent_index,
    names_prefix = "rent_"
  ) |>
  clean_names() |>
  mutate(change = rent_2021_01 - rent_2020_01) |>
  arrange(change) |>
  slice(1:10)

# 7. Display results
print(glue("Observations: {n_obs}"))
print(glue("Unique ZIP codes: {n_zip}"))
print(glue("Unique neighborhoods: {n_neigh}"))

# View COVID drop table
knitr::kable(
  covid_drop,
  caption = "Top 10 ZIP Codes with Largest Rent Decrease (Jan 2020 → Jan 2021)",
  digits = 2
)

# Optional: View missing ZIPs
# knitr::kable(missing_zips)

```
```{r}
covid_drop =
  nyc_rent_df |>
  filter(ym %in% c("2020_01", "2021_01")) |>
  select(zip_code, county, neighborhood, ym, rent_index) |>
  group_by(zip_code, county, neighborhood, ym) |>
  summarise(
    rent_index = mean(rent_index, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = ym,
    values_from = rent_index,
    names_prefix = "rent_"
  ) |>
  janitor::clean_names() |>
  mutate(change = rent_2021_01 - rent_2020_01) |>
  arrange(change) |>
  slice(1:10)

knitr::kable(
  covid_drop,
  caption = "Top 10 ZIP Codes with Largest Rent Decrease (Jan 2020 → Jan 2021)",
  digits = 2
)
```

