p8105_hw2_sc5558
================

``` r
library(tidyverse)
library(janitor)
library(readxl)
library(lubridate)
```

## Problem 1

``` r
# Problem 1

## 1. Clean pols data
pols =
  read_csv("data/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(
    president = if_else(prez_gop == 1, "gop", "dem")
  ) |>
  select(-day, -prez_gop, -prez_dem) |>
  arrange(year, month)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
## 2. Clean snp data
snp =
  read_csv("data/snp.csv") |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  select(year, month, close) |>
  arrange(year, month)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
## 3. Clean unemployment data
unemployment =
  read_csv("data/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment"
  ) |>
  mutate(
    month = str_to_title(month),        # e.g. "Jan" → "Jan"
    month = match(month, month.abb)     # convert abbrev to number 1–12
  ) |>
  arrange(year, month)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
## 4. Merge datasets
merged_df =
  pols |>
  left_join(snp, by = c("year", "month")) |>
  left_join(unemployment, by = c("year", "month"))
## 5. Check structure
dim(merged_df)
```

    ## [1] 822  11

``` r
range(merged_df$year)
```

    ## [1] 1947 2015

``` r
names(merged_df)
```

    ##  [1] "year"         "month"        "gov_gop"      "sen_gop"      "rep_gop"     
    ##  [6] "gov_dem"      "sen_dem"      "rep_dem"      "president"    "close"       
    ## [11] "unemployment"

## Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

The merged dataset contains 822 monthly observations and 11 key
variables. The year ranges from 1947 to 2015. In addition, the names of
the variables include year, month, gov_gop, sen_gop, rep_gop, gov_dem,
sen_dem, rep_dem, president, close, and unemployment.

## Problem 2

``` r
# Problem 2

## 1. Mr. Trash Wheel
mr_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = "A2:N586") |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "mr",
    sports_balls = as.integer(round(sports_balls, 0))
  )

## Mr. Trash Wheel
mr_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             skip = 1) |>   # skips the header note row
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "mr",
    year = as.integer(year),
    sports_balls = as.integer(round(sports_balls, 0))
  )
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
## Professor Trash Wheel
prof_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "professor",
    year = as.integer(year),
  )

## Captain Trash Wheel
captain_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Captain Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "captain",
    year = as.integer(year),
  )

## Gwynns Falls Trash Wheel
gwynns_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel",
             skip = 1) |>
  janitor::clean_names() |>
  drop_na(dumpster) |>
  mutate(
    wheel = "gwynns_falls",
    year = as.integer(year),
  )
## Combine all
trash_df =
  bind_rows(mr_df, prof_df, captain_df, gwynns_df)
```

## Write a paragraph about these data; you are encouraged to use inline R. Be sure to note the number of observations in the resulting dataset, and give examples of key variables. For available data, what was the total weight of trash collected by Professor Trash Wheel? What was the total number of cigarette butts collected by Gwynnda in June of 2022?

``` r
## Summaries for Problem 2

# Total weight collected by Professor Trash Wheel
prof_total_weight =
  trash_df |>
  filter(wheel == "professor") |>
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

# Cigarette butts collected by Gwynns Falls in June 2022
gwynns_cig_butts =
  trash_df |>
  filter(wheel == "gwynns_falls", year == 2022, month == "June") |>
  summarise(total_cig_butts = sum(cigarette_butts, na.rm = TRUE))
```

The combined Trash Wheel dataset contains 1225 observations across 17
variables, representing dumpster-specific collections from Mr.,
Professor, Captain, and Gwynns Falls Trash Wheels. Key variables include
the collection date `(month, year)`, the amount of trash collected in
`weight_tons` and `volume_cubic_yards`, and counts of items such as
`plastic_bottles`, `cigarette_butts`, and `wrappers`. Professor Trash
Wheel collected a total of 282.26 tons of trash. In June 2022, the
Gwynns Falls Trash Wheel collected 1.812^{4} cigarette butts. This tidy
dataset provides a comprehensive view of waste accumulation and
composition across multiple locations in Baltimore’s waterways. \##
Problem 3

``` r
library(tidyverse)
library(janitor)
library(lubridate)
library(glue)

# 1. Read and tidy the Zillow ZORI dataset
zori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  pivot_longer(
    cols = starts_with("20"),             # includes all dates like "2020-01-31"
    names_to = "date",
    values_to = "rent_index"
  ) |>
  mutate(
    date = ymd(date),
    year = year(date),
    month = month(date),
    ym = str_c(year, sprintf("%02d", month), sep = "_"),
    zip_code = as.character(RegionName)
  ) |>
  select(zip_code, date, year, month, ym, rent_index)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# 2. Read and clean ZIP code metadata
zip_df =
  read_csv("data/Zip Codes.csv") |>
  clean_names() |>
  rename(
    zip_code = zip_code,
    county = county,
    neighborhood = neighborhood
  ) |>
  mutate(zip_code = as.character(zip_code))
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
# 3. Merge both datasets
nyc_rent_df =
  left_join(zori_df, zip_df, by = "zip_code") |>
  relocate(zip_code, county, neighborhood, date, rent_index)
```

    ## Warning in left_join(zori_df, zip_df, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 4757 of `x` matches multiple rows in `y`.
    ## ℹ Row 256 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
# 4. Summary statistics
n_obs = nrow(nyc_rent_df)
n_zip = n_distinct(nyc_rent_df$zip_code)
n_neigh = n_distinct(nyc_rent_df$neighborhood)

# 5. Identify ZIP codes missing from Zillow dataset
missing_zips =
  anti_join(zip_df, zori_df, by = "zip_code") |>
  select(zip_code, county, neighborhood)

# 6. COVID rent drop analysis: Jan 2020 vs Jan 2021
covid_drop =
  nyc_rent_df |>
  filter(ym %in% c("2020_01", "2021_01")) |>
  select(zip_code, county, neighborhood, ym, rent_index) |>
  group_by(zip_code, county, neighborhood, ym) |>
  summarise(
    rent_index = mean(rent_index, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from = ym,
    values_from = rent_index,
    names_prefix = "rent_"
  ) |>
  clean_names() |>
  mutate(change = rent_2021_01 - rent_2020_01) |>
  arrange(change) |>
  slice(1:10)

# 7. Display results
print(glue("Observations: {n_obs}"))
```

    ## Observations: 17516

``` r
print(glue("Unique ZIP codes: {n_zip}"))
```

    ## Unique ZIP codes: 149

``` r
print(glue("Unique neighborhoods: {n_neigh}"))
```

    ## Unique neighborhoods: 43

``` r
# View COVID drop table
knitr::kable(
  covid_drop,
  caption = "Top 10 ZIP Codes with Largest Rent Decrease (Jan 2020 → Jan 2021)",
  digits = 2
)
```

| zip_code | county | neighborhood | rent_2020_01 | rent_2021_01 | change |
|:---|:---|:---|---:|---:|---:|
| 10007 | New York | Lower Manhattan | 6334.21 | 5421.61 | -912.60 |
| 10069 | New York | NA | 4623.04 | 3874.92 | -748.12 |
| 10009 | New York | Lower East Side | 3406.44 | 2692.19 | -714.25 |
| 10016 | New York | Gramercy Park and Murray Hill | 3731.14 | 3019.43 | -711.70 |
| 10001 | New York | Chelsea and Clinton | 4108.10 | 3397.65 | -710.45 |
| 10002 | New York | Lower East Side | 3645.42 | 2935.11 | -710.30 |
| 10004 | New York | Lower Manhattan | 3149.66 | 2443.70 | -705.96 |
| 10038 | New York | Lower Manhattan | 3573.20 | 2875.62 | -697.59 |
| 10012 | New York | Greenwich Village and Soho | 3628.57 | 2942.34 | -686.22 |
| 10010 | New York | Gramercy Park and Murray Hill | 3697.28 | 3012.35 | -684.93 |

Top 10 ZIP Codes with Largest Rent Decrease (Jan 2020 → Jan 2021)

## Tidy Dataset Summary

The resulting tidy dataset contains 17516 monthly observations of the
Zillow Observed Rent Index (ZORI) for ZIP codes across New York City,
covering the time span from January 2015 to August 2024. The dataset
includes 149 unique ZIP codes and 43 unique neighborhoods, each
associated with a county (borough), a date, and a rent index value. This
structure enables easy comparison across time and location. \## Zip
codes missing from Zillow’s Dataset A small number of Zip codes in the
ZIP dataset are missing in the dataset, example include:

``` r
knitr::kable(head(missing_zips, 5), caption = "Example ZIP Codes Missing from Zillow Dataset")
```

| zip_code | county | neighborhood               |
|:---------|:-------|:---------------------------|
| 10464    | Bronx  | Southeast Bronx            |
| 10474    | Bronx  | Hunts Point and Mott Haven |
| 10475    | Bronx  | Northeast Bronx            |
| 10499    | Bronx  | NA                         |
| 10550    | Bronx  | NA                         |

Example ZIP Codes Missing from Zillow Dataset

These zipcodes may be excluded for several reasons: some represent
industrial zones, or some are outside NYC boundaries. \## Covid 19 Rent
Drops To examine COVID-related rental price shifts, we compared ZORI
values in January 2020 and January 2021 across ZIP codes. The following
table shows the 10 ZIP codes with the largest drops in rental prices:

``` r
knitr::kable(covid_drop, caption = "Top 10 ZIP Codes with Largest Rent Decrease (Jan 2020 → Jan 2021)", digits = 2)
```

| zip_code | county | neighborhood | rent_2020_01 | rent_2021_01 | change |
|:---|:---|:---|---:|---:|---:|
| 10007 | New York | Lower Manhattan | 6334.21 | 5421.61 | -912.60 |
| 10069 | New York | NA | 4623.04 | 3874.92 | -748.12 |
| 10009 | New York | Lower East Side | 3406.44 | 2692.19 | -714.25 |
| 10016 | New York | Gramercy Park and Murray Hill | 3731.14 | 3019.43 | -711.70 |
| 10001 | New York | Chelsea and Clinton | 4108.10 | 3397.65 | -710.45 |
| 10002 | New York | Lower East Side | 3645.42 | 2935.11 | -710.30 |
| 10004 | New York | Lower Manhattan | 3149.66 | 2443.70 | -705.96 |
| 10038 | New York | Lower Manhattan | 3573.20 | 2875.62 | -697.59 |
| 10012 | New York | Greenwich Village and Soho | 3628.57 | 2942.34 | -686.22 |
| 10010 | New York | Gramercy Park and Murray Hill | 3697.28 | 3012.35 | -684.93 |

Top 10 ZIP Codes with Largest Rent Decrease (Jan 2020 → Jan 2021)

These ZIP codes are primarily in Manhattan (New York County), including
neighborhoods such as Lower Manhattan, Gramercy Park, and Chelsea. In
these areas, rent prices fell by approximately \$670 to over \$900 per
month. This dramatic decline reflects the COVID-19 pandemic’s impact on
urban housing demand, as remote work, outmigration, and temporary
closures led to reduced demand for centrally located rental units
